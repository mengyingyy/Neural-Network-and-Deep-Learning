# Neural-Network-and-Deep-Learning
This respo covers all my work of deep learning course from Georgetown Univeristy.
## HW 1: 
Regularization.Using the accompanying Hitters dataset, explore regression models to predict a player’s Salary from other variables.  
### 1.1
Use LASSO regression to predict Salary from the other numeric predictors.Create a visualization of the coefficient trajectories.Comment on which are thefinal three predictors that remain in the model. Use cross-validation to find the optimal value of the regularization penality.How many predictors are left inthat model?
### 1.2
Repeat with Ridge Regression.Visualize coeffecient trajectories. Use cross-validation to find the optimal vaule of the regularization penalty.
## HW 2:
### 1 Feedforward: Building a ReLU neural net-work
It includes draw a network, write out the mathematical equation for the output of this network, write out the forward-pass function in python and calculate the class probabilities associated with the forward pass of each sample.
### 2 Gradient Descent
This includes calculate the partial derivatives given function of two variables,create a visualization of the contours of this function, write a Gradient Descent algorithm for finding the minimum of the function, visualize results with a few different learning rates, write a Gradient Descent With Momentum algorithm for finding the mini-mum and visualize results with a few different settings of the algorithm’s hyperparameters.
### 3 Backprop
This includes derive expressions of the gradient of the Loss function with respect to each of the model parameters, generate a synthetic dataset like the XOR pattern, fit network using Gradient Descent and keep track of the total Loss at each iteration and plot the result, using Momentum and plot a visualization  of  the  final  decision  boundary  that the model  has learned. Overlay the datapoints in this plot. 
## HW 3:
### 1 Autoencoder
It includes build and fit a convolutional autoencoder for the Fashion MNIST dataset with convolutional classification networks: Conv2D, MaxPooling,and so on. 
### 2 Image Classification
This includes Deep CNN, Tansfer Learning.
### 3 Text Classification
It includes RNN and CNN.
## Neural Style Transfer Project
### Abstract
Nowadays, there are many methods for neural style transfer (NST) task. In our project, we chose two model-optimization-based method – Per-style-per-model and arbitrary-style-per-model. The first one need to train different models for different style pictures. The second method only trains one model to fit all the styles. We compared these two models and evaluate them in the situation of limited dataset and hardware. And we found that these models can work well on different styles.
### Introduction
Neural style transfer (NST) is a neat idea to demonstrate that artificial intelligence can play a part in producing images with artistic attributes. NST builds on the key idea which extract style information form artistic images and recombine them with the content extracted from other natural images to form a new image that both resembles the content image as well as seemingly been “artistically produced” by a professional artist. 
### Please see more details under the  Neural Style Transfer Project 1 and 2 file 

